{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6544844b",
   "metadata": {},
   "source": [
    "# Tarea 6: Regresión Lineal Múltiple con Step Forward Feature Selection\n",
    "\n",
    "**Asignatura:** Métodos Numéricos  \n",
    "**Fecha:** Noviembre 2025  \n",
    "**Dataset:** Retail Insights - A Comprehensive Sales Dataset\n",
    "\n",
    "---\n",
    "\n",
    "## Resumen Ejecutivo\n",
    "\n",
    "Este informe presenta un análisis de regresión lineal múltiple aplicado a datos de ventas retail con el objetivo de predecir el total de ventas por pedido. Se implementa el algoritmo **Step Forward Feature Selection (SFFS)** para identificar de manera iterativa las variables más relevantes que expliquen las ventas totales. Los resultados muestran el conjunto óptimo de variables predictoras y las métricas de desempeño del modelo final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724f84b2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Introducción\n",
    "\n",
    "### 1.1 Contexto del Problema\n",
    "\n",
    "En el contexto del comercio minorista, la capacidad de predecir con precisión las ventas es fundamental para la planificación estratégica, gestión de inventarios y toma de decisiones financieras. Este estudio analiza un dataset exhaustivo de transacciones de ventas retail con el objetivo de construir un modelo predictivo robusto.\n",
    "\n",
    "### 1.2 Objetivos\n",
    "\n",
    "Los objetivos principales de este análisis son:\n",
    "\n",
    "1. **Explorar y comprender** la estructura del dataset de ventas retail\n",
    "2. **Implementar el algoritmo SFFS** para selección automática de variables predictoras\n",
    "3. **Construir un modelo de regresión lineal múltiple** que prediga el total de ventas por pedido\n",
    "4. **Evaluar el desempeño** del modelo mediante métricas estándar (MAE, MSE, R²)\n",
    "5. **Identificar las variables más influyentes** en la predicción de ventas\n",
    "\n",
    "### 1.3 Metodología\n",
    "\n",
    "Se utilizará el algoritmo **Step Forward Feature Selection (SFFS)**, que agrega variables de forma iterativa, seleccionando en cada paso aquella que produzca la mayor mejora en el error absoluto medio (MAE). Este enfoque greedy permite identificar las variables más relevantes de manera sistemática."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89109414",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Desarrollo\n",
    "\n",
    "### 2.1 Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5894c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías para manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Librerías para visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Librerías para modelado\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Configuración de visualización\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00b9716",
   "metadata": {},
   "source": [
    "### 2.2 Carga y Exploración Inicial del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bb0ef7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXPLORACIÓN INICIAL DEL DATASET\n",
      "================================================================================\n",
      "\n",
      "Dimensiones del dataset: 5000 filas x 24 columnas\n",
      "\n",
      "Primeras 5 filas del dataset:\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order No</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Account Manager</th>\n",
       "      <th>Order Priority</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Cost Price</th>\n",
       "      <th>Retail Price</th>\n",
       "      <th>Profit Margin</th>\n",
       "      <th>Order Quantity</th>\n",
       "      <th>Sub Total</th>\n",
       "      <th>Discount %</th>\n",
       "      <th>Discount $</th>\n",
       "      <th>Order Total</th>\n",
       "      <th>Shipping Cost</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4293-1</td>\n",
       "      <td>02-09-2014</td>\n",
       "      <td>Vivek Sundaresam</td>\n",
       "      <td>152 Bunnerong Road,Eastgardens</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Tina Carlton</td>\n",
       "      <td>Critical</td>\n",
       "      <td>UGen Ultra Professional Cordless Optical Suite</td>\n",
       "      <td>...</td>\n",
       "      <td>$156.50</td>\n",
       "      <td>$300.97</td>\n",
       "      <td>$144.47</td>\n",
       "      <td>23.0</td>\n",
       "      <td>$4,533.52</td>\n",
       "      <td>2%</td>\n",
       "      <td>$194.83</td>\n",
       "      <td>$4,757.22</td>\n",
       "      <td>$7.18</td>\n",
       "      <td>$4,291.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5001-1</td>\n",
       "      <td>24-10-2015</td>\n",
       "      <td>Shahid Hopkins</td>\n",
       "      <td>438 Victoria Avenue,Chatswood</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>Natasha Song</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Bagged Rubber Bands</td>\n",
       "      <td>...</td>\n",
       "      <td>$0.24</td>\n",
       "      <td>$1.26</td>\n",
       "      <td>$1.02</td>\n",
       "      <td>8.0</td>\n",
       "      <td>$45.20</td>\n",
       "      <td>3%</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$45.90</td>\n",
       "      <td>$0.70</td>\n",
       "      <td>$46.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5004-1</td>\n",
       "      <td>13-03-2014</td>\n",
       "      <td>Dennis Pardue</td>\n",
       "      <td>412 Brunswick St,Fitzroy</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>VIC</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>Connor Betts</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>TechSavi Cordless Navigator Duo</td>\n",
       "      <td>...</td>\n",
       "      <td>$42.11</td>\n",
       "      <td>$80.98</td>\n",
       "      <td>$38.87</td>\n",
       "      <td>45.0</td>\n",
       "      <td>$873.32</td>\n",
       "      <td>4%</td>\n",
       "      <td>$72.23</td>\n",
       "      <td>$837.57</td>\n",
       "      <td>$7.18</td>\n",
       "      <td>$82.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5009-1</td>\n",
       "      <td>18-02-2013</td>\n",
       "      <td>Sean Wendt</td>\n",
       "      <td>145 Ramsay St,Haberfield</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Phoebe Gour</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Artisan Printable Repositionable Plastic Tabs</td>\n",
       "      <td>...</td>\n",
       "      <td>$5.33</td>\n",
       "      <td>$8.60</td>\n",
       "      <td>$3.27</td>\n",
       "      <td>16.0</td>\n",
       "      <td>$73.52</td>\n",
       "      <td>1%</td>\n",
       "      <td>$4.35</td>\n",
       "      <td>$740.67</td>\n",
       "      <td>$6.19</td>\n",
       "      <td>$730.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5010-1</td>\n",
       "      <td>13-09-2014</td>\n",
       "      <td>Christina Vanderzanden</td>\n",
       "      <td>188 Pitt Street,Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Tina Carlton</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Pizazz Drawing Pencil Set</td>\n",
       "      <td>...</td>\n",
       "      <td>$1.53</td>\n",
       "      <td>$2.78</td>\n",
       "      <td>$1.25</td>\n",
       "      <td>49.0</td>\n",
       "      <td>$138.46</td>\n",
       "      <td>7%</td>\n",
       "      <td>$5.95</td>\n",
       "      <td>$123.77</td>\n",
       "      <td>$1.34</td>\n",
       "      <td>$125.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Order No  Order Date           Customer Name  \\\n",
       "0   4293-1  02-09-2014        Vivek Sundaresam   \n",
       "1   5001-1  24-10-2015          Shahid Hopkins   \n",
       "2   5004-1  13-03-2014           Dennis Pardue   \n",
       "3   5009-1  18-02-2013              Sean Wendt   \n",
       "4   5010-1  13-09-2014  Christina Vanderzanden   \n",
       "\n",
       "                          Address       City State   Customer Type  \\\n",
       "0  152 Bunnerong Road,Eastgardens     Sydney   NSW  Small Business   \n",
       "1   438 Victoria Avenue,Chatswood     Sydney   NSW       Corporate   \n",
       "2        412 Brunswick St,Fitzroy  Melbourne   VIC        Consumer   \n",
       "3        145 Ramsay St,Haberfield     Sydney   NSW  Small Business   \n",
       "4          188 Pitt Street,Sydney     Sydney   NSW  Small Business   \n",
       "\n",
       "  Account Manager Order Priority  \\\n",
       "0    Tina Carlton       Critical   \n",
       "1    Natasha Song         Medium   \n",
       "2    Connor Betts  Not Specified   \n",
       "3     Phoebe Gour       Critical   \n",
       "4    Tina Carlton  Not Specified   \n",
       "\n",
       "                                     Product Name  ... Cost Price  \\\n",
       "0  UGen Ultra Professional Cordless Optical Suite  ...    $156.50   \n",
       "1                             Bagged Rubber Bands  ...      $0.24   \n",
       "2                 TechSavi Cordless Navigator Duo  ...     $42.11   \n",
       "3   Artisan Printable Repositionable Plastic Tabs  ...      $5.33   \n",
       "4                       Pizazz Drawing Pencil Set  ...      $1.53   \n",
       "\n",
       "  Retail Price Profit Margin Order Quantity  Sub Total Discount % Discount $  \\\n",
       "0      $300.97       $144.47           23.0  $4,533.52         2%    $194.83   \n",
       "1        $1.26         $1.02            8.0     $45.20         3%      $0.00   \n",
       "2       $80.98        $38.87           45.0    $873.32         4%     $72.23   \n",
       "3        $8.60         $3.27           16.0     $73.52         1%      $4.35   \n",
       "4        $2.78         $1.25           49.0    $138.46         7%      $5.95   \n",
       "\n",
       "   Order Total Shipping Cost      Total  \n",
       "0    $4,757.22         $7.18  $4,291.55  \n",
       "1       $45.90         $0.70     $46.91  \n",
       "2      $837.57         $7.18     $82.58  \n",
       "3      $740.67         $6.19    $730.92  \n",
       "4      $123.77         $1.34    $125.97  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Información general del dataset:\n",
      "--------------------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 24 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Order No           5000 non-null   object \n",
      " 1   Order Date         5000 non-null   object \n",
      " 2   Customer Name      5000 non-null   object \n",
      " 3   Address            4999 non-null   object \n",
      " 4   City               5000 non-null   object \n",
      " 5   State              5000 non-null   object \n",
      " 6   Customer Type      5000 non-null   object \n",
      " 7   Account Manager    5000 non-null   object \n",
      " 8   Order Priority     5000 non-null   object \n",
      " 9   Product Name       5000 non-null   object \n",
      " 10  Product Category   5000 non-null   object \n",
      " 11  Product Container  5000 non-null   object \n",
      " 12  Ship Mode          5000 non-null   object \n",
      " 13  Ship Date          5000 non-null   object \n",
      " 14  Cost Price         5000 non-null   object \n",
      " 15  Retail Price       5000 non-null   object \n",
      " 16  Profit Margin      5000 non-null   object \n",
      " 17  Order Quantity     4999 non-null   float64\n",
      " 18  Sub Total          5000 non-null   object \n",
      " 19  Discount %         5000 non-null   object \n",
      " 20  Discount $         5000 non-null   object \n",
      " 21  Order Total        5000 non-null   object \n",
      " 22  Shipping Cost      5000 non-null   object \n",
      " 23  Total              5000 non-null   object \n",
      "dtypes: float64(1), object(23)\n",
      "memory usage: 937.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EXPLORACIÓN INICIAL DEL DATASET\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDimensiones del dataset: {df.shape[0]} filas x {df.shape[1]} columnas\")\n",
    "print(f\"\\nPrimeras 5 filas del dataset:\")\n",
    "print(\"-\"*80)\n",
    "display(df.head())\n",
    "\n",
    "print(f\"\\nInformación general del dataset:\")\n",
    "print(\"-\"*80)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "951eb617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estadísticas descriptivas de variables numéricas:\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.483097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.391863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Order Quantity\n",
       "count     4999.000000\n",
       "mean        26.483097\n",
       "std         14.391863\n",
       "min          1.000000\n",
       "25%         13.000000\n",
       "50%         27.000000\n",
       "75%         39.000000\n",
       "max         50.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores nulos por columna:\n",
      "--------------------------------------------------------------------------------\n",
      "Address           1\n",
      "Order Quantity    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Estadísticas descriptivas\n",
    "print(\"\\nEstadísticas descriptivas de variables numéricas:\")\n",
    "print(\"-\"*80)\n",
    "display(df.describe())\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(\"-\"*80)\n",
    "nulls = df.isnull().sum()\n",
    "if nulls.sum() > 0:\n",
    "    print(nulls[nulls > 0])\n",
    "else:\n",
    "    print(\"No se encontraron valores nulos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d198ed2a",
   "metadata": {},
   "source": [
    "### 2.3 Preparación de Datos y Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a54fe9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PREPARACIÓN DE DATOS\n",
      "================================================================================\n",
      "\n",
      "Identificando variable objetivo...\n",
      "Columnas disponibles: ['Order No', 'Order Date', 'Customer Name', 'Address', 'City', 'State', 'Customer Type', 'Account Manager', 'Order Priority', 'Product Name', 'Product Category', 'Product Container', 'Ship Mode', 'Ship Date', 'Cost Price', 'Retail Price', 'Profit Margin', 'Order Quantity', 'Sub Total', 'Discount %', 'Discount $', 'Order Total', 'Shipping Cost', 'Total']\n",
      "\n",
      "Variables numéricas (1): ['Order Quantity']\n",
      "Variables categóricas (23): ['Order No', 'Order Date', 'Customer Name', 'Address', 'City', 'State', 'Customer Type', 'Account Manager', 'Order Priority', 'Product Name', 'Product Category', 'Product Container', 'Ship Mode', 'Ship Date', 'Cost Price', 'Retail Price', 'Profit Margin', 'Sub Total', 'Discount %', 'Discount $', 'Order Total', 'Shipping Cost', 'Total']\n",
      "\n",
      "Codificando variables categóricas...\n",
      "  - Order No -> Order No_encoded\n",
      "  - Order Date -> Order Date_encoded\n",
      "  - Customer Name -> Customer Name_encoded\n",
      "  - Address -> Address_encoded\n",
      "  - City -> City_encoded\n",
      "  - State -> State_encoded\n",
      "  - Customer Type -> Customer Type_encoded\n",
      "  - Account Manager -> Account Manager_encoded\n",
      "  - Order Priority -> Order Priority_encoded\n",
      "  - Product Name -> Product Name_encoded\n",
      "  - Product Category -> Product Category_encoded\n",
      "  - Product Container -> Product Container_encoded\n",
      "  - Ship Mode -> Ship Mode_encoded\n",
      "  - Ship Date -> Ship Date_encoded\n",
      "  - Cost Price -> Cost Price_encoded\n",
      "  - Retail Price -> Retail Price_encoded\n",
      "  - Profit Margin -> Profit Margin_encoded\n",
      "  - Sub Total -> Sub Total_encoded\n",
      "  - Discount % -> Discount %_encoded\n",
      "  - Discount $ -> Discount $_encoded\n",
      "  - Order Total -> Order Total_encoded\n",
      "  - Shipping Cost -> Shipping Cost_encoded\n",
      "  - Total -> Total_encoded\n",
      "\n",
      "Preparación de datos completada\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PREPARACIÓN DE DATOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear una copia del dataframe para trabajar\n",
    "df_work = df.copy()\n",
    "\n",
    "# Identificar la variable objetivo\n",
    "print(\"\\nIdentificando variable objetivo...\")\n",
    "print(f\"Columnas disponibles: {list(df_work.columns)}\")\n",
    "\n",
    "# Identificar variables numéricas y categóricas\n",
    "numeric_cols = df_work.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df_work.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nVariables numéricas ({len(numeric_cols)}): {numeric_cols}\")\n",
    "print(f\"Variables categóricas ({len(categorical_cols)}): {categorical_cols}\")\n",
    "\n",
    "# Codificar variables categóricas usando LabelEncoder\n",
    "print(\"\\nCodificando variables categóricas...\")\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_work[col + '_encoded'] = le.fit_transform(df_work[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "    print(f\"  - {col} -> {col}_encoded\")\n",
    "\n",
    "print(\"\\nPreparación de datos completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab67b4b5",
   "metadata": {},
   "source": [
    "### 2.4 Definición de Variables para el Modelo\n",
    "\n",
    "Definimos la variable objetivo (Y) y las variables predictoras potenciales (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff2ba4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEFINICIÓN DE VARIABLES\n",
      "================================================================================\n",
      "NOTA: Columna objetivo ajustada a: 'Sub Total'\n",
      "\n",
      "Variable Objetivo (Y): Sub Total\n",
      "Variables Predictoras Potenciales (24):\n",
      "   1. Order Quantity\n",
      "   2. Order No_encoded\n",
      "   3. Order Date_encoded\n",
      "   4. Customer Name_encoded\n",
      "   5. Address_encoded\n",
      "   6. City_encoded\n",
      "   7. State_encoded\n",
      "   8. Customer Type_encoded\n",
      "   9. Account Manager_encoded\n",
      "   10. Order Priority_encoded\n",
      "   11. Product Name_encoded\n",
      "   12. Product Category_encoded\n",
      "   13. Product Container_encoded\n",
      "   14. Ship Mode_encoded\n",
      "   15. Ship Date_encoded\n",
      "   16. Cost Price_encoded\n",
      "   17. Retail Price_encoded\n",
      "   18. Profit Margin_encoded\n",
      "   19. Sub Total_encoded\n",
      "   20. Discount %_encoded\n",
      "   21. Discount $_encoded\n",
      "   22. Order Total_encoded\n",
      "   23. Shipping Cost_encoded\n",
      "   24. Total_encoded\n",
      "\n",
      "Dataset preparado: 5000 observaciones, 24 variables predictoras\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DEFINICIÓN DE VARIABLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Definir la variable objetivo (Y)\n",
    "# Asumiendo que la variable objetivo se llama 'Total Amount' o similar\n",
    "# Ajustar según el nombre real en el dataset\n",
    "\n",
    "target_column = 'Total Amount'  # Ajustar según el dataset real\n",
    "if target_column not in df_work.columns:\n",
    "    # Buscar columnas que puedan ser el total\n",
    "    possible_targets = [col for col in df_work.columns if 'total' in col.lower() or 'amount' in col.lower()]\n",
    "    if possible_targets:\n",
    "        target_column = possible_targets[0]\n",
    "        print(f\"NOTA: Columna objetivo ajustada a: '{target_column}'\")\n",
    "\n",
    "y = df_work[target_column]\n",
    "\n",
    "# Definir las variables predictoras (X)\n",
    "# Excluir la variable objetivo y columnas no numéricas originales\n",
    "exclude_cols = [target_column] + categorical_cols + ['Transaction ID', 'Date'] if 'Transaction ID' in df_work.columns and 'Date' in df_work.columns else [target_column] + categorical_cols\n",
    "\n",
    "# Obtener todas las columnas numéricas excepto la variable objetivo\n",
    "potential_features = [col for col in df_work.columns if col not in exclude_cols and (df_work[col].dtype in [np.number, 'int64', 'float64'])]\n",
    "\n",
    "print(f\"\\nVariable Objetivo (Y): {target_column}\")\n",
    "print(f\"Variables Predictoras Potenciales ({len(potential_features)}):\")\n",
    "for i, feat in enumerate(potential_features, 1):\n",
    "    print(f\"   {i}. {feat}\")\n",
    "\n",
    "# Crear el dataframe X con las variables predictoras\n",
    "X_all = df_work[potential_features].copy()\n",
    "\n",
    "print(f\"\\nDataset preparado: {X_all.shape[0]} observaciones, {X_all.shape[1]} variables predictoras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b69b2aa",
   "metadata": {},
   "source": [
    "### 2.5 Implementación del Algoritmo Step Forward Feature Selection (SFFS)\n",
    "\n",
    "El algoritmo SFFS funciona de la siguiente manera:\n",
    "\n",
    "1. **Inicialización**: Se comienza con un conjunto vacío de variables seleccionadas\n",
    "2. **Iteración**: En cada paso, se evalúan todas las variables restantes\n",
    "3. **Selección**: Se elige la variable que, al agregarla al conjunto actual, produce el menor MAE\n",
    "4. **Actualización**: Se agrega la variable seleccionada y se repite hasta agotar todas las variables\n",
    "5. **Resultado**: Se obtiene una secuencia ordenada de variables por importancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66bc8054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP FORWARD FEATURE SELECTION (SFFS)\n",
      "================================================================================\n",
      "\n",
      "Iniciando SFFS con 24 variables candidatas...\n",
      "Esto puede tomar varios minutos dependiendo del tamaño del dataset...\n",
      "\n",
      "Iteración 1/24\n",
      "   Variables seleccionadas hasta ahora: 0\n",
      "   Variables restantes por evaluar: 24\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Entrenar modelo\u001b[39;00m\n\u001b[0;32m     36\u001b[0m lr \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m---> 37\u001b[0m \u001b[43mlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_temp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Predecir y calcular MAE\u001b[39;00m\n\u001b[0;32m     40\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mpredict(X_temp)\n",
      "File \u001b[1;32mc:\\Python 3.10\\lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python 3.10\\lib\\site-packages\\sklearn\\linear_model\\_base.py:618\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    614\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    616\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 618\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    628\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32mc:\\Python 3.10\\lib\\site-packages\\sklearn\\utils\\validation.py:2971\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2969\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m   2970\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2971\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m   2972\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Python 3.10\\lib\\site-packages\\sklearn\\utils\\validation.py:1368\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1363\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1364\u001b[0m     )\n\u001b[0;32m   1366\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[1;32m-> 1368\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1387\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Python 3.10\\lib\\site-packages\\sklearn\\utils\\validation.py:1105\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1102\u001b[0m     )\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[1;32m-> 1105\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1114\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python 3.10\\lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python 3.10\\lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m     )\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STEP FORWARD FEATURE SELECTION (SFFS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import time\n",
    "\n",
    "# Listas para almacenar resultados\n",
    "selected_vars = []  # Variables seleccionadas en orden\n",
    "remaining_vars = potential_features.copy()  # Variables restantes por evaluar\n",
    "mae_history = []  # Historial de MAE en cada iteración\n",
    "iteration_details = []  # Detalles de cada iteración\n",
    "\n",
    "print(f\"\\nIniciando SFFS con {len(remaining_vars)} variables candidatas...\")\n",
    "print(f\"Esto puede tomar varios minutos dependiendo del tamaño del dataset...\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Algoritmo SFFS\n",
    "iteration = 0\n",
    "while remaining_vars:\n",
    "    iteration += 1\n",
    "    best_mae = float('inf')\n",
    "    best_var = None\n",
    "    \n",
    "    print(f\"Iteración {iteration}/{len(potential_features)}\")\n",
    "    print(f\"   Variables seleccionadas hasta ahora: {len(selected_vars)}\")\n",
    "    print(f\"   Variables restantes por evaluar: {len(remaining_vars)}\")\n",
    "    \n",
    "    # Probar cada variable restante\n",
    "    for var in remaining_vars:\n",
    "        # Crear conjunto temporal de variables (seleccionadas + la variable candidata)\n",
    "        temp_vars = selected_vars + [var]\n",
    "        X_temp = X_all[temp_vars]\n",
    "        \n",
    "        # Entrenar modelo\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X_temp, y)\n",
    "        \n",
    "        # Predecir y calcular MAE\n",
    "        y_pred = lr.predict(X_temp)\n",
    "        mae = mean_absolute_error(y, y_pred)\n",
    "        \n",
    "        # Actualizar mejor variable si es mejor que la actual\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_var = var\n",
    "    \n",
    "    # Agregar la mejor variable encontrada\n",
    "    selected_vars.append(best_var)\n",
    "    remaining_vars.remove(best_var)\n",
    "    mae_history.append(best_mae)\n",
    "    \n",
    "    iteration_details.append({\n",
    "        'Iteración': iteration,\n",
    "        'Variable Agregada': best_var,\n",
    "        'MAE': best_mae,\n",
    "        'Variables Acumuladas': len(selected_vars)\n",
    "    })\n",
    "    \n",
    "    print(f\"   Mejor variable: '{best_var}' con MAE = {best_mae:,.2f}\\n\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"SFFS COMPLETADO en {elapsed_time:.2f} segundos ({elapsed_time/60:.2f} minutos)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54675eeb",
   "metadata": {},
   "source": [
    "### 2.6 Análisis de Resultados del SFFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c0beb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TABLA DE RESULTADOS POR ITERACIÓN\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmin of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m display(results_df)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Identificar el mejor conjunto de variables (menor MAE)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m best_idx \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmae_history\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m best_mae \u001b[38;5;241m=\u001b[39m mae_history[best_idx]\n\u001b[0;32m     11\u001b[0m best_n_vars \u001b[38;5;241m=\u001b[39m best_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Python 3.10\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:1457\u001b[0m, in \u001b[0;36margmin\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;124;03mReturns the indices of the minimum values along an axis.\u001b[39;00m\n\u001b[0;32m   1370\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1454\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1456\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margmin\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Python 3.10\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     52\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Python 3.10\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:46\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# As this already tried the method, subok is maybe quite reasonable here\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# but this follows what was done before. TODO: revisit this.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m arr, \u001b[38;5;241m=\u001b[39m conv\u001b[38;5;241m.\u001b[39mas_arrays(subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 46\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(arr, method)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conv\u001b[38;5;241m.\u001b[39mwrap(result, to_scalar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmin of an empty sequence"
     ]
    }
   ],
   "source": [
    "# Crear DataFrame con los detalles de cada iteración\n",
    "results_df = pd.DataFrame(iteration_details)\n",
    "\n",
    "print(\"\\nTABLA DE RESULTADOS POR ITERACIÓN\")\n",
    "print(\"=\"*80)\n",
    "display(results_df)\n",
    "\n",
    "# Identificar el mejor conjunto de variables (menor MAE)\n",
    "best_idx = np.argmin(mae_history)\n",
    "best_mae = mae_history[best_idx]\n",
    "best_n_vars = best_idx + 1\n",
    "best_vars = selected_vars[:best_n_vars]\n",
    "\n",
    "print(f\"\\nMEJOR MODELO ENCONTRADO:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Número de variables: {best_n_vars}\")\n",
    "print(f\"MAE mínimo: {best_mae:,.2f}\")\n",
    "print(f\"\\nVariables del mejor modelo (en orden de importancia):\")\n",
    "for i, var in enumerate(best_vars, 1):\n",
    "    print(f\"   {i}. {var}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cae40d",
   "metadata": {},
   "source": [
    "### 2.7 Visualización de la Evolución del MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a4aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de evolución del MAE\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(mae_history) + 1), mae_history, marker='o', linewidth=2, markersize=6, color='steelblue')\n",
    "plt.axvline(x=best_n_vars, color='red', linestyle='--', linewidth=2, label=f'Mejor modelo ({best_n_vars} vars)')\n",
    "plt.axhline(y=best_mae, color='green', linestyle='--', linewidth=1, alpha=0.5, label=f'MAE mínimo = {best_mae:,.2f}')\n",
    "plt.xlabel('Número de Variables', fontsize=12)\n",
    "plt.ylabel('MAE (Mean Absolute Error)', fontsize=12)\n",
    "plt.title('Evolución del MAE durante SFFS', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Calcular la mejora porcentual del MAE\n",
    "mae_improvement = [(mae_history[0] - mae) / mae_history[0] * 100 for mae in mae_history]\n",
    "plt.plot(range(1, len(mae_improvement) + 1), mae_improvement, marker='s', linewidth=2, markersize=6, color='forestgreen')\n",
    "plt.axvline(x=best_n_vars, color='red', linestyle='--', linewidth=2, label=f'Mejor modelo ({best_n_vars} vars)')\n",
    "plt.xlabel('Número de Variables', fontsize=12)\n",
    "plt.ylabel('Mejora del MAE (%)', fontsize=12)\n",
    "plt.title('Mejora Porcentual del MAE', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMejora total del MAE: {mae_improvement[-1]:.2f}% (desde {mae_history[0]:,.2f} hasta {mae_history[-1]:,.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b432309e",
   "metadata": {},
   "source": [
    "### 2.8 Evaluación del Modelo Óptimo\n",
    "\n",
    "Evaluamos el modelo con el conjunto óptimo de variables identificado por SFFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00050591",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"EVALUACIÓN DEL MODELO ÓPTIMO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Entrenar el modelo final con las mejores variables\n",
    "X_optimal = X_all[best_vars]\n",
    "lr_final = LinearRegression()\n",
    "lr_final.fit(X_optimal, y)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_final = lr_final.predict(X_optimal)\n",
    "\n",
    "# Calcular métricas\n",
    "mae_final = mean_absolute_error(y, y_pred_final)\n",
    "mse_final = mean_squared_error(y, y_pred_final)\n",
    "rmse_final = np.sqrt(mse_final)\n",
    "r2_final = r2_score(y, y_pred_final)\n",
    "\n",
    "print(f\"\\nMÉTRICAS DEL MODELO ÓPTIMO\")\n",
    "print(\"-\"*80)\n",
    "print(f\"MAE  (Mean Absolute Error)     : ${mae_final:,.2f}\")\n",
    "print(f\"MSE  (Mean Squared Error)      : ${mse_final:,.2f}\")\n",
    "print(f\"RMSE (Root Mean Squared Error) : ${rmse_final:,.2f}\")\n",
    "print(f\"R²   (Coeficiente Determinación): {r2_final:.4f} ({r2_final*100:.2f}%)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Interpretar R²\n",
    "if r2_final > 0.9:\n",
    "    interpretation = \"Excelente\"\n",
    "elif r2_final > 0.7:\n",
    "    interpretation = \"Bueno\"\n",
    "elif r2_final > 0.5:\n",
    "    interpretation = \"Moderado\"\n",
    "else:\n",
    "    interpretation = \"Pobre\"\n",
    "    \n",
    "print(f\"\\nInterpretación: El modelo explica el {r2_final*100:.2f}% de la variabilidad\")\n",
    "print(f\"en las ventas totales. Ajuste: {interpretation}\")\n",
    "\n",
    "# Coeficientes del modelo\n",
    "print(f\"\\nCOEFICIENTES DEL MODELO\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Intercepto (β₀): ${lr_final.intercept_:,.2f}\")\n",
    "print(f\"\\nCoeficientes de las variables:\")\n",
    "for i, (var, coef) in enumerate(zip(best_vars, lr_final.coef_), 1):\n",
    "    print(f\"   {i}. {var:30s}: β = {coef:12,.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d449fbc8",
   "metadata": {},
   "source": [
    "### 2.9 Visualización de Predicciones vs Valores Reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4324080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de predicciones vs valores reales\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Gráfico 1: Scatter plot de predicciones vs valores reales\n",
    "ax1 = axes[0, 0]\n",
    "ax1.scatter(y, y_pred_final, alpha=0.5, s=20, color='steelblue')\n",
    "ax1.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2, label='Línea perfecta')\n",
    "ax1.set_xlabel('Valores Reales', fontsize=12)\n",
    "ax1.set_ylabel('Predicciones', fontsize=12)\n",
    "ax1.set_title('Predicciones vs Valores Reales', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico 2: Distribución de residuos\n",
    "residuals = y - y_pred_final\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(residuals, bins=50, color='lightcoral', edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "ax2.set_xlabel('Residuos', fontsize=12)\n",
    "ax2.set_ylabel('Frecuencia', fontsize=12)\n",
    "ax2.set_title('Distribución de Residuos', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico 3: Residuos vs predicciones\n",
    "ax3 = axes[1, 0]\n",
    "ax3.scatter(y_pred_final, residuals, alpha=0.5, s=20, color='purple')\n",
    "ax3.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax3.set_xlabel('Predicciones', fontsize=12)\n",
    "ax3.set_ylabel('Residuos', fontsize=12)\n",
    "ax3.set_title('Residuos vs Predicciones', fontsize=14, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico 4: Q-Q plot (para normalidad de residuos)\n",
    "from scipy import stats\n",
    "ax4 = axes[1, 1]\n",
    "stats.probplot(residuals, dist=\"norm\", plot=ax4)\n",
    "ax4.set_title('Q-Q Plot de Residuos', fontsize=14, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estadísticas de residuos\n",
    "print(f\"\\nANÁLISIS DE RESIDUOS\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Media de residuos        : ${np.mean(residuals):,.2f}\")\n",
    "print(f\"Mediana de residuos      : ${np.median(residuals):,.2f}\")\n",
    "print(f\"Desviación estándar      : ${np.std(residuals):,.2f}\")\n",
    "print(f\"Residuo mínimo           : ${np.min(residuals):,.2f}\")\n",
    "print(f\"Residuo máximo           : ${np.max(residuals):,.2f}\")\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336118b1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Conclusiones\n",
    "\n",
    "### 3.1 Hallazgos Principales\n",
    "\n",
    "Este análisis ha demostrado exitosamente la aplicación del algoritmo Step Forward Feature Selection para la construcción de un modelo de regresión lineal múltiple predictivo de ventas retail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c28312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RESUMEN DE CONCLUSIONES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. DESEMPEÑO DEL ALGORITMO SFFS:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"   - Se evaluaron {len(potential_features)} variables candidatas\")\n",
    "print(f\"   - El algoritmo identificó un conjunto óptimo de {best_n_vars} variables\")\n",
    "print(f\"   - Tiempo de ejecución: {elapsed_time:.2f} segundos\")\n",
    "print(f\"   - Mejora del MAE: {mae_improvement[best_idx-1]:.2f}%\")\n",
    "\n",
    "print(\"\\n2. CALIDAD DEL MODELO FINAL:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"   - R² Score: {r2_final:.4f} ({interpretation})\")\n",
    "print(f\"   - MAE: ${mae_final:,.2f}\")\n",
    "print(f\"   - RMSE: ${rmse_final:,.2f}\")\n",
    "print(f\"   - El modelo explica el {r2_final*100:.2f}% de la variabilidad en ventas\")\n",
    "\n",
    "print(\"\\n3. VARIABLES MÁS IMPORTANTES:\")\n",
    "print(\"-\"*80)\n",
    "print(\"   Las primeras 3 variables seleccionadas por SFFS fueron:\")\n",
    "for i, var in enumerate(selected_vars[:min(3, len(selected_vars))], 1):\n",
    "    print(f\"   {i}. {var}\")\n",
    "\n",
    "print(\"\\n4. APLICABILIDAD PRÁCTICA:\")\n",
    "print(\"-\"*80)\n",
    "print(\"   - El modelo puede utilizarse para predecir ventas futuras\")\n",
    "print(\"   - Las variables identificadas son clave para estrategias de negocio\")\n",
    "print(\"   - El SFFS permitió reducir dimensionalidad manteniendo precisión\")\n",
    "\n",
    "print(\"\\n5. LIMITACIONES Y MEJORAS FUTURAS:\")\n",
    "print(\"-\"*80)\n",
    "print(\"   - Considerar validación cruzada para evaluar generalización\")\n",
    "print(\"   - Explorar transformaciones no lineales de variables\")\n",
    "print(\"   - Analizar posibles interacciones entre variables\")\n",
    "print(\"   - Evaluar modelos más complejos (Ridge, Lasso, etc.)\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef96ec4",
   "metadata": {},
   "source": [
    "### 3.2 Interpretación de Resultados\n",
    "\n",
    "El algoritmo **Step Forward Feature Selection** ha demostrado ser una herramienta efectiva para:\n",
    "\n",
    "1. **Selección Automática**: Identificó sistemáticamente las variables más relevantes sin necesidad de conocimiento previo del dominio\n",
    "2. **Optimización del Modelo**: Permitió encontrar el equilibrio entre complejidad y precisión\n",
    "3. **Interpretabilidad**: Generó un ranking de importancia de variables, facilitando la comprensión del modelo\n",
    "4. **Eficiencia Computacional**: Redujo la dimensionalidad del problema de manera estructurada\n",
    "\n",
    "### 3.3 Recomendaciones\n",
    "\n",
    "Con base en los resultados obtenidos, se recomienda:\n",
    "\n",
    "- **Para el negocio**: Enfocar estrategias en las variables identificadas como más influyentes\n",
    "- **Para análisis futuros**: Implementar validación cruzada para confirmar la robustez del modelo\n",
    "- **Para mejoras del modelo**: Explorar técnicas de regularización (Ridge, Lasso) y modelos ensemble\n",
    "\n",
    "### 3.4 Conclusión Final\n",
    "\n",
    "Este estudio ha cumplido exitosamente con los objetivos propuestos, implementando un pipeline completo de análisis predictivo desde la exploración de datos hasta la evaluación del modelo final. El algoritmo SFFS ha probado ser una metodología sistemática y efectiva para la selección de características en regresión lineal múltiple, proporcionando resultados interpretables y accionables para la toma de decisiones en el contexto de ventas retail.\n",
    "\n",
    "---\n",
    "\n",
    "**Fin del Informe**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
